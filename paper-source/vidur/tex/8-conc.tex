\vspace{-0.5em}
\section{Conclusion}
\label{sec-conc}


LLM inference efficiency depends on a large number of configuration knobs such as the type or degree of parallelism, scheduling strategy, GPU SKUs. It is impractical to run all possible configurations on actual hardware. In this paper, we present \sysname: a high fidelity and easily extensible simulator for LLM inference, along with a benchmark and search suite. \sysname answers deployment related what-if questions that identify efficient deployment strategies for production environments and helps in evaluating the efficacy of various systems optimizations at nominal cost.

